{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_excel('taipei_running_data_x.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_excel('taipei_running_data_y.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data       土地移轉總面積(平方公尺)  工  住  商  其他  交易筆棟數_土地  交易筆棟數_建物  交易筆棟數_車位      移轉層次  \\\n",
      "0          0.039182  0  1  0   0  0.035714       0.1  0.166667  0.222222   \n",
      "1          0.031495  0  1  0   0  0.071429       0.1  0.083333  0.305556   \n",
      "2          0.027822  0  1  0   0  0.035714       0.1  0.083333  0.194444   \n",
      "3          0.038581  0  0  1   0  0.035714       0.1  0.000000  0.333333   \n",
      "4          0.019160  0  0  1   0  0.035714       0.1  0.000000  0.194444   \n",
      "...             ... .. .. ..  ..       ...       ...       ...       ...   \n",
      "8675       0.123999  0  1  0   0  0.035714       0.1  0.083333  0.138889   \n",
      "8676       0.035054  0  0  1   0  0.071429       0.1  0.083333  0.527778   \n",
      "8677       0.003803  0  0  1   0  0.035714       0.1  0.000000  0.416667   \n",
      "8678       0.105976  0  1  0   0  0.071429       0.1  0.083333  0.444444   \n",
      "8679       0.022752  0  0  1   0  0.071429       0.1  0.083333  0.416667   \n",
      "\n",
      "          總樓層數  ...  其他.1  坡道平面  坡道機械  塔式車位  空格   交易標的橫坐標   交易標的縱坐標        屋齡  \\\n",
      "0     0.354839  ...     0     1     0     0   0  0.579262  0.337162  0.076814   \n",
      "1     0.580645  ...     0     1     0     0   0  0.787888  0.552158  0.349705   \n",
      "2     0.161290  ...     0     0     1     0   0  0.955935  0.566542  0.154290   \n",
      "3     0.161290  ...     0     0     0     0   1  0.787764  0.575805  0.587993   \n",
      "4     0.193548  ...     0     0     0     0   1  0.385013  0.411777  0.312172   \n",
      "...        ...  ...   ...   ...   ...   ...  ..       ...       ...       ...   \n",
      "8675  0.064516  ...     0     1     0     0   0  0.257360  0.938373  0.455022   \n",
      "8676  0.387097  ...     0     0     0     1   0  0.201220  0.899203  0.118175   \n",
      "8677  0.419355  ...     0     0     0     0   1  0.491442  0.068974  0.133822   \n",
      "8678  0.290323  ...     0     1     0     0   0  0.834381  0.518110  0.151075   \n",
      "8679  0.741935  ...     0     1     0     0   0  0.385760  0.260271  0.018577   \n",
      "\n",
      "           lat       lon  \n",
      "0     0.337084  0.578431  \n",
      "1     0.551303  0.788577  \n",
      "2     0.565061  0.957067  \n",
      "3     0.574945  0.788577  \n",
      "4     0.412331  0.384167  \n",
      "...        ...       ...  \n",
      "8675  0.939232  0.258638  \n",
      "8676  0.900243  0.202169  \n",
      "8677  0.069242  0.489153  \n",
      "8678  0.517093  0.834989  \n",
      "8679  0.260850  0.384206  \n",
      "\n",
      "[8680 rows x 46 columns]\n",
      "y_data       單價(元/平方公尺)\n",
      "0         268677\n",
      "1         176252\n",
      "2          98789\n",
      "3         171451\n",
      "4         153983\n",
      "...          ...\n",
      "8675       88643\n",
      "8676      175131\n",
      "8677      175953\n",
      "8678      222855\n",
      "8679      268212\n",
      "\n",
      "[8680 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_data\",x_data)\n",
    "print(\"y_data\",y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train       土地移轉總面積(平方公尺)  工  住  商  其他  交易筆棟數_土地  交易筆棟數_建物  交易筆棟數_車位      移轉層次  \\\n",
      "252        0.037590  0  1  0   0  0.071429       0.1  0.000000  0.250000   \n",
      "1839       0.017292  0  0  1   0  0.035714       0.1  0.083333  0.555556   \n",
      "718        0.028911  0  0  1   0  0.071429       0.1  0.083333  0.222222   \n",
      "3667       0.039654  0  1  0   0  0.035714       0.1  0.166667  0.361111   \n",
      "2883       0.007167  0  0  0   1  0.035714       0.1  0.000000  0.555556   \n",
      "...             ... .. .. ..  ..       ...       ...       ...       ...   \n",
      "4373       0.024572  0  1  0   0  0.035714       0.1  0.083333  0.472222   \n",
      "7891       0.014171  0  1  0   0  0.107143       0.1  0.000000  0.305556   \n",
      "4859       0.018657  0  0  1   0  0.035714       0.1  0.000000  0.277778   \n",
      "3264       0.027319  0  1  0   0  0.035714       0.1  0.000000  0.277778   \n",
      "2732       0.017357  0  0  1   0  0.035714       0.1  0.000000  0.194444   \n",
      "\n",
      "          總樓層數  ...  其他.1  坡道平面  坡道機械  塔式車位  空格   交易標的橫坐標   交易標的縱坐標        屋齡  \\\n",
      "252   0.096774  ...     0     0     0     0   1  0.556793  0.113008  0.557031   \n",
      "1839  0.548387  ...     0     1     0     0   0  0.391050  0.446445  0.002033   \n",
      "718   0.290323  ...     0     1     0     0   0  0.260534  0.357653  0.395604   \n",
      "3667  0.225806  ...     0     1     0     0   0  0.253563  0.845234  0.002316   \n",
      "2883  0.516129  ...     0     0     0     0   1  0.630423  0.422747  0.120444   \n",
      "...        ...  ...   ...   ...   ...   ...  ..       ...       ...       ...   \n",
      "4373  0.322581  ...     0     1     0     0   0  0.428892  0.503105  0.549752   \n",
      "7891  0.387097  ...     0     0     0     0   1  0.012821  0.828004  0.146490   \n",
      "4859  0.322581  ...     0     0     0     0   1  0.381776  0.480286  0.675490   \n",
      "3264  0.096774  ...     0     0     0     0   1  0.956681  0.541550  0.386197   \n",
      "2732  0.258065  ...     0     0     0     0   1  0.480115  0.071355  0.317041   \n",
      "\n",
      "           lat       lon  \n",
      "252   0.113049  0.554818  \n",
      "1839  0.446973  0.390379  \n",
      "718   0.358611  0.259197  \n",
      "3667  0.846123  0.254410  \n",
      "2883  0.422476  0.630118  \n",
      "...        ...       ...  \n",
      "4373  0.503499  0.428566  \n",
      "7891  0.829616  0.012968  \n",
      "4859  0.480837  0.381245  \n",
      "3264  0.540071  0.957678  \n",
      "2732  0.071660  0.477819  \n",
      "\n",
      "[6510 rows x 46 columns]\n",
      "y_train       單價(元/平方公尺)\n",
      "252       105163\n",
      "1839      223151\n",
      "718       125183\n",
      "3667      198987\n",
      "2883      244144\n",
      "...          ...\n",
      "4373      152647\n",
      "7891      140647\n",
      "4859      133067\n",
      "3264      142426\n",
      "2732      157404\n",
      "\n",
      "[6510 rows x 1 columns]\n",
      "X_test       土地移轉總面積(平方公尺)  工  住  商  其他  交易筆棟數_土地  交易筆棟數_建物  交易筆棟數_車位      移轉層次  \\\n",
      "2405       0.011929  0  0  1   0  0.035714       0.1  0.083333  0.222222   \n",
      "8454       0.073522  0  1  0   0  0.107143       0.1  0.000000  0.222222   \n",
      "6657       0.058733  0  1  0   0  0.035714       0.1  0.083333  0.250000   \n",
      "8037       0.017292  0  0  1   0  0.035714       0.1  0.083333  0.222222   \n",
      "8317       0.054897  0  1  0   0  0.071429       0.1  0.166667  0.472222   \n",
      "...             ... .. .. ..  ..       ...       ...       ...       ...   \n",
      "991        0.008337  0  0  1   0  0.035714       0.1  0.083333  0.166667   \n",
      "4824       0.049567  0  1  0   0  0.035714       0.2  0.083333  0.166667   \n",
      "8168       0.049161  0  1  0   0  0.035714       0.1  0.083333  0.361111   \n",
      "899        0.028554  0  0  1   0  0.035714       0.1  0.083333  0.222222   \n",
      "6209       0.067248  0  1  0   0  0.035714       0.1  0.083333  0.250000   \n",
      "\n",
      "          總樓層數  ...  其他.1  坡道平面  坡道機械  塔式車位  空格   交易標的橫坐標   交易標的縱坐標        屋齡  \\\n",
      "2405  0.419355  ...     0     0     0     0   0  0.573100  0.279934  0.028173   \n",
      "8454  0.064516  ...     0     0     0     0   1  0.493372  0.257115  0.858048   \n",
      "6657  0.290323  ...     0     1     0     0   0  0.811726  0.616423  0.028220   \n",
      "8037  0.387097  ...     0     1     0     0   0  0.657434  0.389631  0.174569   \n",
      "8317  0.419355  ...     0     1     0     0   0  0.642870  0.435424  0.103522   \n",
      "...        ...  ...   ...   ...   ...   ...  ..       ...       ...       ...   \n",
      "991   0.387097  ...     0     0     1     0   0  0.371071  0.454931  0.248357   \n",
      "4824  0.258065  ...     0     0     0     0   0  0.455966  0.765497  0.299267   \n",
      "8168  0.290323  ...     0     1     0     0   0  0.254061  0.896099  0.011676   \n",
      "899   0.709677  ...     0     1     0     0   0  0.654011  0.054745  0.030820   \n",
      "6209  0.387097  ...     0     1     0     0   0  0.251883  0.283763  0.061073   \n",
      "\n",
      "           lat       lon  \n",
      "2405  0.279888  0.571974  \n",
      "8454  0.257342  0.491993  \n",
      "6657  0.615469  0.812807  \n",
      "8037  0.389272  0.657015  \n",
      "8317  0.435108  0.642654  \n",
      "...        ...       ...  \n",
      "991   0.455522  0.370399  \n",
      "4824  0.765751  0.456955  \n",
      "8168  0.896975  0.255139  \n",
      "899   0.054462  0.651893  \n",
      "6209  0.284761  0.250197  \n",
      "\n",
      "[2170 rows x 46 columns]\n",
      "y_test       單價(元/平方公尺)\n",
      "2405      241861\n",
      "8454      196381\n",
      "6657      160366\n",
      "8037      192215\n",
      "8317      246117\n",
      "...          ...\n",
      "991       250170\n",
      "4824      162378\n",
      "8168      216122\n",
      "899       133692\n",
      "6209      156446\n",
      "\n",
      "[2170 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\",X_train)\n",
    "print(\"y_train\",y_train)\n",
    "print(\"X_test\",X_test)\n",
    "print(\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200,input_dim=46,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(loss='mean_absolute_percentage_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               9400      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 36,029\n",
      "Trainable params: 36,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6510/6510 [==============================] - 1s 96us/sample - loss: 99.9582\n",
      "Epoch 2/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 97.8945\n",
      "Epoch 3/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 78.7773\n",
      "Epoch 4/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 31.3875\n",
      "Epoch 5/500\n",
      "6510/6510 [==============================] - 0s 36us/sample - loss: 24.1574\n",
      "Epoch 6/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 23.8131\n",
      "Epoch 7/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 23.6025\n",
      "Epoch 8/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 23.4406\n",
      "Epoch 9/500\n",
      "6510/6510 [==============================] - 0s 22us/sample - loss: 23.3279\n",
      "Epoch 10/500\n",
      "6510/6510 [==============================] - ETA: 0s - loss: 23.54 - 0s 23us/sample - loss: 23.2221\n",
      "Epoch 11/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 23.1479\n",
      "Epoch 12/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 23.0761\n",
      "Epoch 13/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 23.0367\n",
      "Epoch 14/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 22.9663\n",
      "Epoch 15/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 22.8983\n",
      "Epoch 16/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 22.8518\n",
      "Epoch 17/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.8153\n",
      "Epoch 18/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.7638\n",
      "Epoch 19/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.7245\n",
      "Epoch 20/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.6814\n",
      "Epoch 21/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 22.6480\n",
      "Epoch 22/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.6436\n",
      "Epoch 23/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.5886\n",
      "Epoch 24/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 22.5559\n",
      "Epoch 25/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.5396\n",
      "Epoch 26/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.5046\n",
      "Epoch 27/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.4854\n",
      "Epoch 28/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 22.4529\n",
      "Epoch 29/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.4396\n",
      "Epoch 30/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.4063\n",
      "Epoch 31/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.4003\n",
      "Epoch 32/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 22.3906\n",
      "Epoch 33/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 22.3575\n",
      "Epoch 34/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.3832\n",
      "Epoch 35/500\n",
      "6510/6510 [==============================] - 0s 37us/sample - loss: 22.3494\n",
      "Epoch 36/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 22.2857\n",
      "Epoch 37/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.3019\n",
      "Epoch 38/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.2748\n",
      "Epoch 39/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 22.2589\n",
      "Epoch 40/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 22.2592\n",
      "Epoch 41/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 22.2548\n",
      "Epoch 42/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 22.2399\n",
      "Epoch 43/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 22.2298s - loss: 22.\n",
      "Epoch 44/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.2489\n",
      "Epoch 45/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 22.1902\n",
      "Epoch 46/500\n",
      "6510/6510 [==============================] - 0s 36us/sample - loss: 22.2033\n",
      "Epoch 47/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.1919\n",
      "Epoch 48/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.1652\n",
      "Epoch 49/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.1659\n",
      "Epoch 50/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.1541\n",
      "Epoch 51/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 22.1741\n",
      "Epoch 52/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.1504\n",
      "Epoch 53/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 22.1419\n",
      "Epoch 54/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 22.1262\n",
      "Epoch 55/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.1130\n",
      "Epoch 56/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 22.1191\n",
      "Epoch 57/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 22.1047\n",
      "Epoch 58/500\n",
      "6510/6510 [==============================] - 0s 37us/sample - loss: 22.1051\n",
      "Epoch 59/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.0819\n",
      "Epoch 60/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.0928\n",
      "Epoch 61/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 22.0929\n",
      "Epoch 62/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0917\n",
      "Epoch 63/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0462\n",
      "Epoch 64/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.0903\n",
      "Epoch 65/500\n",
      "6510/6510 [==============================] - 0s 36us/sample - loss: 22.0529\n",
      "Epoch 66/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 22.0766\n",
      "Epoch 67/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 22.0558\n",
      "Epoch 68/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0599\n",
      "Epoch 69/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 22.0507\n",
      "Epoch 70/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 22.0230\n",
      "Epoch 71/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 22.0544\n",
      "Epoch 72/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.0345\n",
      "Epoch 73/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0580\n",
      "Epoch 74/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0306\n",
      "Epoch 75/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 22.0456\n",
      "Epoch 76/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 22.0263\n",
      "Epoch 77/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 22.0136\n",
      "Epoch 78/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 22.0162\n",
      "Epoch 79/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.0429\n",
      "Epoch 80/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 22.0169\n",
      "Epoch 81/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0430\n",
      "Epoch 82/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 22.0012\n",
      "Epoch 83/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 22.0002\n",
      "Epoch 84/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 22.0093\n",
      "Epoch 85/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 22.0106\n",
      "Epoch 86/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.9868\n",
      "Epoch 87/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 21.9985\n",
      "Epoch 88/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.9856\n",
      "Epoch 89/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 22.0069\n",
      "Epoch 90/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.9938\n",
      "Epoch 91/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9901\n",
      "Epoch 92/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.9908\n",
      "Epoch 93/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9913\n",
      "Epoch 94/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.9876\n",
      "Epoch 95/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.9675\n",
      "Epoch 96/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.9763\n",
      "Epoch 97/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.9740\n",
      "Epoch 98/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9752\n",
      "Epoch 99/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.9696\n",
      "Epoch 100/500\n",
      "6510/6510 [==============================] - 0s 20us/sample - loss: 21.9708\n",
      "Epoch 101/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.9558\n",
      "Epoch 102/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9877\n",
      "Epoch 103/500\n",
      "6510/6510 [==============================] - 0s 20us/sample - loss: 21.9489\n",
      "Epoch 104/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.9877s - loss: 21.\n",
      "Epoch 105/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9486\n",
      "Epoch 106/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9585\n",
      "Epoch 107/500\n",
      "6510/6510 [==============================] - 0s 22us/sample - loss: 21.9616\n",
      "Epoch 108/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.9410\n",
      "Epoch 109/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.9270\n",
      "Epoch 110/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9380\n",
      "Epoch 111/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9485\n",
      "Epoch 112/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9401\n",
      "Epoch 113/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9478\n",
      "Epoch 114/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9291\n",
      "Epoch 115/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.9518\n",
      "Epoch 116/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 21.9443\n",
      "Epoch 117/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9754\n",
      "Epoch 118/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 22.0069\n",
      "Epoch 119/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9393\n",
      "Epoch 120/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.9685\n",
      "Epoch 121/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.9351\n",
      "Epoch 122/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.9830\n",
      "Epoch 123/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 21.9246\n",
      "Epoch 124/500\n",
      "6510/6510 [==============================] - 0s 36us/sample - loss: 21.9185\n",
      "Epoch 125/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9202s - loss: 2\n",
      "Epoch 126/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.9531\n",
      "Epoch 127/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.9104\n",
      "Epoch 128/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.9449\n",
      "Epoch 129/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 21.9220\n",
      "Epoch 130/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.9390\n",
      "Epoch 131/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9384\n",
      "Epoch 132/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9252\n",
      "Epoch 133/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.9159\n",
      "Epoch 134/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.9084\n",
      "Epoch 135/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9640\n",
      "Epoch 136/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.9224\n",
      "Epoch 137/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9497\n",
      "Epoch 138/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9054\n",
      "Epoch 139/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.9214\n",
      "Epoch 140/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.9182\n",
      "Epoch 141/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.9510\n",
      "Epoch 142/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.9074\n",
      "Epoch 143/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.9157\n",
      "Epoch 144/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8970\n",
      "Epoch 145/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9070\n",
      "Epoch 146/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9007\n",
      "Epoch 147/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8876\n",
      "Epoch 148/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 21.9160\n",
      "Epoch 149/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8963\n",
      "Epoch 150/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.9124\n",
      "Epoch 151/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.9070\n",
      "Epoch 152/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.9119\n",
      "Epoch 153/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.9010\n",
      "Epoch 154/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9035\n",
      "Epoch 155/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8908\n",
      "Epoch 156/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8926\n",
      "Epoch 157/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8904\n",
      "Epoch 158/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8947\n",
      "Epoch 159/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.9008\n",
      "Epoch 160/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.9036\n",
      "Epoch 161/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.8817\n",
      "Epoch 162/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.9105\n",
      "Epoch 163/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.8945\n",
      "Epoch 164/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.9033\n",
      "Epoch 165/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.9015\n",
      "Epoch 166/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8888\n",
      "Epoch 167/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8944\n",
      "Epoch 168/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8734\n",
      "Epoch 169/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9043\n",
      "Epoch 170/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.8885\n",
      "Epoch 171/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8772\n",
      "Epoch 172/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8796\n",
      "Epoch 173/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8840\n",
      "Epoch 174/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 21.8974\n",
      "Epoch 175/500\n",
      "6510/6510 [==============================] - 0s 22us/sample - loss: 21.8941\n",
      "Epoch 176/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8933\n",
      "Epoch 177/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.8879\n",
      "Epoch 178/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8712\n",
      "Epoch 179/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8756\n",
      "Epoch 180/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8751\n",
      "Epoch 181/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.9101\n",
      "Epoch 182/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8870\n",
      "Epoch 184/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8787\n",
      "Epoch 185/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8674\n",
      "Epoch 186/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8601\n",
      "Epoch 187/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.8870\n",
      "Epoch 188/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8890\n",
      "Epoch 189/500\n",
      "6510/6510 [==============================] - 0s 20us/sample - loss: 21.8704\n",
      "Epoch 190/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.8723\n",
      "Epoch 191/500\n",
      "6510/6510 [==============================] - 0s 22us/sample - loss: 21.8601\n",
      "Epoch 192/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8711\n",
      "Epoch 193/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8830\n",
      "Epoch 194/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8687\n",
      "Epoch 195/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.8711\n",
      "Epoch 196/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8815\n",
      "Epoch 197/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8764\n",
      "Epoch 198/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8704\n",
      "Epoch 199/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8665\n",
      "Epoch 200/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8704\n",
      "Epoch 201/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8644\n",
      "Epoch 202/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8593\n",
      "Epoch 203/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8607\n",
      "Epoch 204/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 21.8593\n",
      "Epoch 205/500\n",
      "6510/6510 [==============================] - 0s 41us/sample - loss: 21.8557\n",
      "Epoch 206/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8672\n",
      "Epoch 207/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.8660\n",
      "Epoch 208/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8590\n",
      "Epoch 209/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8595\n",
      "Epoch 210/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8688\n",
      "Epoch 211/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8589\n",
      "Epoch 212/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8566\n",
      "Epoch 213/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8816\n",
      "Epoch 214/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8527\n",
      "Epoch 215/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8604\n",
      "Epoch 216/500\n",
      "6510/6510 [==============================] - 0s 28us/sample - loss: 21.8661\n",
      "Epoch 217/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.8578\n",
      "Epoch 218/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.8525\n",
      "Epoch 219/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8600\n",
      "Epoch 220/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8610\n",
      "Epoch 221/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8637\n",
      "Epoch 222/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8592\n",
      "Epoch 223/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8713\n",
      "Epoch 224/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8458\n",
      "Epoch 225/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8656\n",
      "Epoch 226/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8698\n",
      "Epoch 227/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8466\n",
      "Epoch 228/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8854\n",
      "Epoch 229/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8450\n",
      "Epoch 230/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8445\n",
      "Epoch 231/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8338\n",
      "Epoch 232/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8558\n",
      "Epoch 233/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8455\n",
      "Epoch 234/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8429\n",
      "Epoch 235/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8333\n",
      "Epoch 236/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8561\n",
      "Epoch 237/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8591\n",
      "Epoch 238/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8478\n",
      "Epoch 239/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8781\n",
      "Epoch 240/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8551\n",
      "Epoch 241/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8448\n",
      "Epoch 242/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8303\n",
      "Epoch 243/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8560\n",
      "Epoch 244/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8771\n",
      "Epoch 245/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8465\n",
      "Epoch 246/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8499\n",
      "Epoch 247/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8441\n",
      "Epoch 248/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8505\n",
      "Epoch 249/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8547\n",
      "Epoch 250/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8401\n",
      "Epoch 251/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8395\n",
      "Epoch 252/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8504\n",
      "Epoch 253/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8539\n",
      "Epoch 254/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8404\n",
      "Epoch 255/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8393\n",
      "Epoch 256/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8649\n",
      "Epoch 257/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8557\n",
      "Epoch 258/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8404\n",
      "Epoch 259/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8453\n",
      "Epoch 260/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8263\n",
      "Epoch 261/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8356\n",
      "Epoch 262/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8408\n",
      "Epoch 263/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8458\n",
      "Epoch 264/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8484\n",
      "Epoch 265/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8510\n",
      "Epoch 266/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8196\n",
      "Epoch 267/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8446\n",
      "Epoch 268/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8790\n",
      "Epoch 269/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8536\n",
      "Epoch 270/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8353\n",
      "Epoch 271/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8211\n",
      "Epoch 272/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8510\n",
      "Epoch 273/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8266\n",
      "Epoch 274/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8425\n",
      "Epoch 275/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8284\n",
      "Epoch 276/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8422\n",
      "Epoch 277/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.8744\n",
      "Epoch 278/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8245\n",
      "Epoch 279/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8303\n",
      "Epoch 280/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8433\n",
      "Epoch 281/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8308\n",
      "Epoch 282/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8205\n",
      "Epoch 283/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8401\n",
      "Epoch 284/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8326\n",
      "Epoch 285/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8433\n",
      "Epoch 286/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8464\n",
      "Epoch 287/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8411\n",
      "Epoch 288/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8459\n",
      "Epoch 289/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8291\n",
      "Epoch 290/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8276\n",
      "Epoch 291/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8235\n",
      "Epoch 292/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8384\n",
      "Epoch 293/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8291\n",
      "Epoch 294/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8242\n",
      "Epoch 295/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8394\n",
      "Epoch 296/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8235\n",
      "Epoch 297/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8516\n",
      "Epoch 298/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8344\n",
      "Epoch 299/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8211\n",
      "Epoch 300/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8273\n",
      "Epoch 301/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8284\n",
      "Epoch 302/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8316\n",
      "Epoch 303/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8342\n",
      "Epoch 304/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8307\n",
      "Epoch 305/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8223\n",
      "Epoch 306/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8486\n",
      "Epoch 307/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8311\n",
      "Epoch 308/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.8138\n",
      "Epoch 309/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8182\n",
      "Epoch 310/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8374\n",
      "Epoch 311/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8390\n",
      "Epoch 312/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8182\n",
      "Epoch 313/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8526\n",
      "Epoch 314/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.8265\n",
      "Epoch 315/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8394\n",
      "Epoch 316/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.8288\n",
      "Epoch 317/500\n",
      "6510/6510 [==============================] - 0s 22us/sample - loss: 21.8301\n",
      "Epoch 318/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.8280\n",
      "Epoch 319/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8207\n",
      "Epoch 320/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.8609\n",
      "Epoch 321/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.8240\n",
      "Epoch 322/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8176\n",
      "Epoch 323/500\n",
      "6510/6510 [==============================] - 0s 22us/sample - loss: 21.8188\n",
      "Epoch 324/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 21.8251\n",
      "Epoch 325/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 21.8297\n",
      "Epoch 326/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8484s - loss: 21.\n",
      "Epoch 327/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.8200\n",
      "Epoch 328/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8179\n",
      "Epoch 329/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.8180\n",
      "Epoch 330/500\n",
      "6510/6510 [==============================] - 0s 24us/sample - loss: 21.8192\n",
      "Epoch 331/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8302\n",
      "Epoch 332/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8440\n",
      "Epoch 333/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8146\n",
      "Epoch 334/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8153\n",
      "Epoch 335/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8166\n",
      "Epoch 336/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8183\n",
      "Epoch 337/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8166\n",
      "Epoch 338/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8682\n",
      "Epoch 339/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8227\n",
      "Epoch 340/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8066\n",
      "Epoch 341/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8214\n",
      "Epoch 342/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8304\n",
      "Epoch 343/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8068\n",
      "Epoch 344/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8252\n",
      "Epoch 345/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8509\n",
      "Epoch 346/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8346\n",
      "Epoch 347/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8028\n",
      "Epoch 348/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8425\n",
      "Epoch 349/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8016\n",
      "Epoch 350/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8430\n",
      "Epoch 351/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8015\n",
      "Epoch 352/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8073\n",
      "Epoch 353/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8165\n",
      "Epoch 354/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8323\n",
      "Epoch 355/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8112\n",
      "Epoch 356/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8192\n",
      "Epoch 357/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8218\n",
      "Epoch 358/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8101\n",
      "Epoch 359/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.8187\n",
      "Epoch 360/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8255\n",
      "Epoch 361/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7941\n",
      "Epoch 362/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7919\n",
      "Epoch 363/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8185\n",
      "Epoch 364/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7897\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8060\n",
      "Epoch 366/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8022\n",
      "Epoch 367/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8416\n",
      "Epoch 368/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8146\n",
      "Epoch 369/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8143\n",
      "Epoch 370/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8575\n",
      "Epoch 371/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8265\n",
      "Epoch 372/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7830\n",
      "Epoch 373/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8136\n",
      "Epoch 374/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8144\n",
      "Epoch 375/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8106\n",
      "Epoch 376/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8105\n",
      "Epoch 377/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8097\n",
      "Epoch 378/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.7997\n",
      "Epoch 379/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8137\n",
      "Epoch 380/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8046\n",
      "Epoch 381/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8017\n",
      "Epoch 382/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7816\n",
      "Epoch 383/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8076\n",
      "Epoch 384/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8364\n",
      "Epoch 385/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.8022\n",
      "Epoch 386/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7869\n",
      "Epoch 387/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7938\n",
      "Epoch 388/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7891\n",
      "Epoch 389/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7828\n",
      "Epoch 390/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7896\n",
      "Epoch 391/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7794\n",
      "Epoch 392/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7832\n",
      "Epoch 393/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7981\n",
      "Epoch 394/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8251\n",
      "Epoch 395/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8284\n",
      "Epoch 396/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8042\n",
      "Epoch 397/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7808\n",
      "Epoch 398/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8027\n",
      "Epoch 399/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7836\n",
      "Epoch 400/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7867\n",
      "Epoch 401/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7835\n",
      "Epoch 402/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7899\n",
      "Epoch 403/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7917\n",
      "Epoch 404/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.8058\n",
      "Epoch 405/500\n",
      "6510/6510 [==============================] - 0s 25us/sample - loss: 21.8216\n",
      "Epoch 406/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7841\n",
      "Epoch 407/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8337\n",
      "Epoch 408/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8063\n",
      "Epoch 409/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7740\n",
      "Epoch 410/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7699\n",
      "Epoch 411/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7902\n",
      "Epoch 412/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8043\n",
      "Epoch 413/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8003\n",
      "Epoch 414/500\n",
      "6510/6510 [==============================] - 0s 27us/sample - loss: 21.7961\n",
      "Epoch 415/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7617\n",
      "Epoch 416/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7719\n",
      "Epoch 417/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7686\n",
      "Epoch 418/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8012\n",
      "Epoch 419/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.8623\n",
      "Epoch 420/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8069\n",
      "Epoch 421/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7758\n",
      "Epoch 422/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.7967\n",
      "Epoch 423/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7887\n",
      "Epoch 424/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7728\n",
      "Epoch 425/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7765\n",
      "Epoch 426/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.8035\n",
      "Epoch 427/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7793\n",
      "Epoch 428/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7764\n",
      "Epoch 429/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7803\n",
      "Epoch 430/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7753\n",
      "Epoch 431/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7619\n",
      "Epoch 432/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7762\n",
      "Epoch 433/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7573\n",
      "Epoch 434/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7867\n",
      "Epoch 435/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.7721\n",
      "Epoch 436/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7839\n",
      "Epoch 437/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7663\n",
      "Epoch 438/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7552\n",
      "Epoch 439/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7883\n",
      "Epoch 440/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7642\n",
      "Epoch 441/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7728\n",
      "Epoch 442/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7534\n",
      "Epoch 443/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7637\n",
      "Epoch 444/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.7630\n",
      "Epoch 445/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.8019\n",
      "Epoch 446/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7543\n",
      "Epoch 447/500\n",
      "6510/6510 [==============================] - 0s 36us/sample - loss: 21.7776\n",
      "Epoch 448/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7836\n",
      "Epoch 449/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7614\n",
      "Epoch 450/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7956\n",
      "Epoch 451/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7554\n",
      "Epoch 452/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.7618\n",
      "Epoch 453/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7764\n",
      "Epoch 454/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7575\n",
      "Epoch 455/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7521\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.7727\n",
      "Epoch 457/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.7628\n",
      "Epoch 458/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7493\n",
      "Epoch 459/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7686\n",
      "Epoch 460/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7646\n",
      "Epoch 461/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.7610\n",
      "Epoch 462/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.7610\n",
      "Epoch 463/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7855\n",
      "Epoch 464/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7326\n",
      "Epoch 465/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7529\n",
      "Epoch 466/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7393\n",
      "Epoch 467/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7661\n",
      "Epoch 468/500\n",
      "6510/6510 [==============================] - 0s 30us/sample - loss: 21.7395\n",
      "Epoch 469/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7336\n",
      "Epoch 470/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7352\n",
      "Epoch 471/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7384\n",
      "Epoch 472/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7300\n",
      "Epoch 473/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7505\n",
      "Epoch 474/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7326\n",
      "Epoch 475/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7566\n",
      "Epoch 476/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7537\n",
      "Epoch 477/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7450\n",
      "Epoch 478/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7475\n",
      "Epoch 479/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7521\n",
      "Epoch 480/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7358\n",
      "Epoch 481/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7373\n",
      "Epoch 482/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7193\n",
      "Epoch 483/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7503\n",
      "Epoch 484/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7605\n",
      "Epoch 485/500\n",
      "6510/6510 [==============================] - 0s 23us/sample - loss: 21.7431\n",
      "Epoch 486/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.7222\n",
      "Epoch 487/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.7466\n",
      "Epoch 488/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.7571\n",
      "Epoch 489/500\n",
      "6510/6510 [==============================] - 0s 36us/sample - loss: 21.7268\n",
      "Epoch 490/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.7232\n",
      "Epoch 491/500\n",
      "6510/6510 [==============================] - 0s 21us/sample - loss: 21.7203\n",
      "Epoch 492/500\n",
      "6510/6510 [==============================] - 0s 20us/sample - loss: 21.7174\n",
      "Epoch 493/500\n",
      "6510/6510 [==============================] - 0s 26us/sample - loss: 21.7207\n",
      "Epoch 494/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.7112\n",
      "Epoch 495/500\n",
      "6510/6510 [==============================] - 0s 32us/sample - loss: 21.7095\n",
      "Epoch 496/500\n",
      "6510/6510 [==============================] - 0s 34us/sample - loss: 21.7315\n",
      "Epoch 497/500\n",
      "6510/6510 [==============================] - 0s 29us/sample - loss: 21.7071\n",
      "Epoch 498/500\n",
      "6510/6510 [==============================] - 0s 33us/sample - loss: 21.7181\n",
      "Epoch 499/500\n",
      "6510/6510 [==============================] - 0s 35us/sample - loss: 21.7211\n",
      "Epoch 500/500\n",
      "6510/6510 [==============================] - 0s 31us/sample - loss: 21.7061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x254582f8108>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=100,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in X_train.columns.tolist():\n",
    "    #print(i)\n",
    "    #print(np.sum(X_train[i].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2170"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.90757115107304"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE(y_test,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(result,columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [price]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['price']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>單價(元/平方公尺)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      單價(元/平方公尺)\n",
       "1376           0\n",
       "380            0\n",
       "7642           0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test['單價(元/平方公尺)']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139700.39], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
