{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料讀取與資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看資料的 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改變資料的 shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一個 Channel，從 (28,28) → (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(10000,28,28,1)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認更改後資料的 shape 是否正確"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進行 one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "print(y_train.shape,y_test.shape,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始建立 CNN 神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀入必要的函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 打造函數學習機 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3),padding='same', input_shape=(28,28,1), activation='relu')) #輸出 16 個 28*28 矩陣，事實上是 (28,28,16)\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #Maximum Pooling Output = (14,14,16)\n",
    "model.add(Conv2D(32,(5,5),padding='same', activation='relu')) #輸出 32 個 14*14 矩陣，事實上是 (14,14,32)\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #Maximum Pooling Output = (7,7,32)\n",
    "model.add(Conv2D(64,(5,5),padding='same', activation='relu')) #輸出 64 個 7*7 矩陣，事實上是 (7,7,64)\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #Maximum Pooling Output = (3,3,64)\n",
    "model.add(Conv2D(128,(3,3),padding='same', activation='relu')) #輸出 128 個 3*3 矩陣，事實上是 (3,3,128)\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #Maximum Pooling Output = (3,3,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) #拉平神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(120, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸出層為10個神經元\n",
    "## 激勵函數 : softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢視神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               15480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 154,802\n",
      "Trainable params: 154,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d = ( 3 x 3 + 1 ) x 16 = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d_1 = (( 5 x 5 x 16 ) + 1 ) x 32 = 12832"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d_2 = (( 5 x 5 x 32 ) + 1 ) x 64 = 51264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d_3 = (( 3 x 3 x 64 ) + 1 ) x 128 = 73856"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 x 1 x 128 = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense = 128 x 120 + 120 = 15480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense_1 = 120 x 10 + 10 = 1210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失函數 : mae\n",
    "## 優化器 : Adam \n",
    "## Adam 優化器之參數設置 : learning_rate=0.001, beta_1=0.9, beta_2=0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae',optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch size 設置為 100\n",
    "## 訓練次數為 30 次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 59s 991us/sample - loss: 0.0842 - accuracy: 0.5843\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 59s 989us/sample - loss: 0.0550 - accuracy: 0.7276\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 58s 965us/sample - loss: 0.0324 - accuracy: 0.8399\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 58s 959us/sample - loss: 0.0268 - accuracy: 0.8679- loss: 0.0268 - \n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 59s 978us/sample - loss: 0.0249 - accuracy: 0.8771\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0231 - accuracy: 0.8857\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0222 - accuracy: 0.8900\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0210 - accuracy: 0.8958\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0204 - accuracy: 0.8986\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 63s 1ms/sample - loss: 0.0198 - accuracy: 0.9016\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: 0.0193 - accuracy: 0.9037\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: 0.0187 - accuracy: 0.9067\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0186 - accuracy: 0.9070\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0179 - accuracy: 0.9113\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0178 - accuracy: 0.9115\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0177 - accuracy: 0.9120\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0178 - accuracy: 0.9117\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0173 - accuracy: 0.9139\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0171 - accuracy: 0.9148\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 59s 981us/sample - loss: 0.0168 - accuracy: 0.9163\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0169 - accuracy: 0.9158\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 60s 998us/sample - loss: 0.0162 - accuracy: 0.9189\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 60s 993us/sample - loss: 0.0168 - accuracy: 0.9159\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0161 - accuracy: 0.9196\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0165 - accuracy: 0.9176\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0165 - accuracy: 0.9178\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 58s 973us/sample - loss: 0.0162 - accuracy: 0.9193-\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 57s 953us/sample - loss: 0.0166 - accuracy: 0.9172\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 55s 924us/sample - loss: 0.0162 - accuracy: 0.9188\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 58s 959us/sample - loss: 0.0161 - accuracy: 0.9194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2501b0a1cc8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=100,epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelname_dict = {\n",
    "    0:'T-shirt/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f74ffec8d1b4dc4ab1a9cb937db7bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='測試編號', max=9999), Button(description='Run Interact', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_xy(測試編號=0):\n",
    "    ax = plt.gca()\n",
    "    X = x_test[測試編號]\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28),cmap='Greys')\n",
    "    print(f'神經網路預測的答案為: {labelname_dict[result[測試編號]]}')\n",
    "interact_manual(predict_xy,測試編號=(0,9999));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路預測是: Bag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2501d4fd3c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARk0lEQVR4nO3daYzVVZrH8d/TiAsCKjsiyiIa0DilVpDARCBmXHghEtPjknQwwdAv0DSJ0TFo0iZGozjdHWNGE1zSzKTbTms3ERMyIzEmblG8osMiOrgUgiBVuIGgLOUzL+o6KbH+zynv7pzvJ6ncqv9T597D5f7qLud/zjF3F4D//37R7A4AaAzCDmSCsAOZIOxAJgg7kIljGnljI0aM8AkTJjTyJoGsdHR0aM+ePdZXraqwm9nlkh6UNEDSY+5+X/T7EyZMUKlUquYmAQTa29sLaxW/jDezAZL+TdIVkqZJus7MplV6fQDqq5r37NMlve/uH7r7IUl/kTS/Nt0CUGvVhH2cpO29ft5RPvYDZrbYzEpmVurq6qri5gBUo5qw9/UhwI/OvXX3Fe7e7u7tI0eOrOLmAFSjmrDvkDS+18+nSdpZXXcA1Es1YX9D0hQzm2hmx0q6VtLq2nQLQK1VPPTm7kfM7CZJ/6Weobcn3H1zzXoGoKaqGmd39zWS1tSoLwDqiNNlgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiATVW3ZbGYdkvZJ6pZ0xN3ba9EpALVXVdjL5rr7nhpcD4A64mU8kIlqw+6SnjOzN81scV+/YGaLzaxkZqWurq4qbw5ApaoN+yx3v0DSFZKWmNnFR/+Cu69w93Z3bx85cmSVNwegUlWF3d13li87Ja2SNL0WnQJQexWH3cxONLMh338v6VJJm2rVMQC1Vc2n8aMlrTKz76/nz+7+nzXp1c/MgQMHwvoJJ5wQ1r/77ruwfujQobB+zDHF/40DBw4M2zbTkSNHqqqnlB+bffrFL+Lnue7u7oqvW5K++eabsB5JPZ5GjBhRWHP3wlrFYXf3DyX9Q6XtATQWQ29AJgg7kAnCDmSCsAOZIOxAJmoxESYLL7/8cmFt6dKlYdtSqRTWBwwYENZTQ3ednZ2FtQcffDBsO3HixLA+fXp8ntSkSZPC+uDBgwtr0ZBhf+r1lBqaS9UPHjwY1ocOHVpYO/nkk8O20bBeNPTGMzuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5lo+EBmNA6YkppWWI1rr702rE+ePLmwtmjRorDtjTfeGNbPPPPMsH777beH9VGjRhXWLr300rDtbbfdFtbXrVsX1lPTULdt21ZYa2trC9tOmDAhrH/88cdhPZo6nFo1KXXbw4cPr6r9scceW1iLzpuQ4nF4xtkBEHYgF4QdyARhBzJB2IFMEHYgE4QdyERDx9ndPRyXrWbZ43feeSesP/LII2H9zjvvDOvnnntuYW3lypVh29S/a8OGDWF99uzZYf3pp58urM2YMSNs+8ADD4T11NzqnTt3hvWob6kx+tT/6QcffBDWhw0bVli75JJLwrafffZZWE+dfzB16tSwvnnz5sJaai58tEYA4+wACDuQC8IOZIKwA5kg7EAmCDuQCcIOZKKh4+xmFo45p+a6L1u2rLCWmrf90EMPxZ2ro9T656nx5nHjxoX1aD576vyBaL65lN5OesGCBWH9sssuK6y99tprYdtBgwaF9dRYdjRWfuqpp4ZtU+cXvP/++2E92mdAivcKSP1/V7qVdfKZ3cyeMLNOM9vU69gwM1trZlvLl6dUdOsAGqY/L+P/KOnyo47dLul5d58i6fnyzwBaWDLs7v6ipM+POjxf0vfniK6UdFWN+wWgxir9gG60u++SpPJl4ZtGM1tsZiUzK3V1dVV4cwCqVfdP4919hbu3u3t7apE/APVTadh3m9lYSSpfxsthAmi6SsO+WtLC8vcLJT1Tm+4AqJfkOLuZPSlpjqQRZrZD0m8l3Sfpr2a2SNLHkn5Zi86k5lbffPPNhbXUuGlKd3d3WI/GRVPzrlNzo0ePHh3Wd+/eHdanTZtWWHv11VfDttHcaEk677zzwnpqTPi9994rrKXGsvfu3RvWU/drNN9948aNYdshQ4aE9c8/P/oz6x+K9l+XpHfffbewltr7PVqTPjpXJRl2d7+uoBTP/gfQUjhdFsgEYQcyQdiBTBB2IBOEHchEQ6e4fvvtt+Ew1dy5c8P20fBaatpfapppaipnNPQWbb/bH2PGjAnr+/btC+unnFI86TA1NBYtkS1J+/fvD+tPPfVUWP/qq68Ka2PHjg3blkqlsJ7asvmiiy4qrHV0dIRt9+zZE9a/+OKLsP7ss8+G9WiZ6wsvvDBse/jw4cIaS0kDIOxALgg7kAnCDmSCsAOZIOxAJgg7kImGjrN3d3eHY8bnn39+xdedGkdPLVMdjaOnpKagpqaRdnbGa3+kpqmec845hbXt27eHbSdOnBjWU0tNt7W1hfXo/IfUeHLq3IdNmzaF9WhlpNR9fsYZZ4T1M888s+LbluJlstesWRO2XbJkSVgvwjM7kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZaOg4+969e/Xcc88V1lNj4TNmzKi4rZlVVa/G8uXLw3pqSeUXXnghrEfLGs+cOTNsm1qu+dChQ2E9Na87+rdFc7ol6Zprrgnr0VLRUjyXf/LkyWHb1HkXqfM6oqWipXgdgQMHDoRtDx48WFhjPjsAwg7kgrADmSDsQCYIO5AJwg5kgrADmWjoOPuQIUM0e/bswvpjjz0Wto/G2VPj5Klx+JTo+lPzrlPz0efNmxfWly1bFtZXr15dWNu6dWvYdvz48WE9tX7666+/HtajNe2//PLLsG205rwUz+OXpNNPP72wdtxxx4Vt77777rB+wQUXhPXosSpJU6dOLay98sorYdtoO+lou+fkM7uZPWFmnWa2qdexu8zsEzN7u/wVP1oBNF1/Xsb/UdLlfRz/g7u3lb/ipTUANF0y7O7+oqTi8zEB/CxU8wHdTWa2ofwyv/CNmZktNrOSmZVS79EA1E+lYX9E0mRJbZJ2Sfpd0S+6+wp3b3f39tSEDwD1U1HY3X23u3e7+3eSHpU0vbbdAlBrFYXdzHrvtbtAUrymL4CmS46zm9mTkuZIGmFmOyT9VtIcM2uT5JI6JP26Pzc2ePBgXXzxxYX1tWvXhu1XrlxZWFu4cGHYtp7j8Kk1xlPj8CmpfciHDx9eWPvoo4/Ctqm93+fPnx/Wd+7cGdajdeO//vrrsG1qzfqXXnoprEf7EKTOL0iNk8+dOzesjxo1Kqx/8sknhbUXX3wxbBuddxHNw0+G3d2v6+Pw46l2AFoLp8sCmSDsQCYIO5AJwg5kgrADmWjoFNeU1LTCBQsWFNZS2yJfffXVYb2eS0mnhr9S9WiYRpKuvPLKwlpqS+ZouWVJOuGEE8J6SrTscWop6GiJbElat25dWF+/fn1hbejQoWHbaKqolF7uObVlczT1eOzYsYU1SRo4cGBhLXoc88wOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmWmqcPWXVqlWFtTvuuCNsm5o2eP/994f1448/vrCWWgq6o6MjrJ922mlhfenSpWE9WnI59e/etWtXWE/1bfTo0WH9rLPOKqyNGDEibJs6R2DWrFlhvZpppJs3bw7rGzduDOtnn312WI+2yo6mLEvS4cOHC2ts2QyAsAO5IOxAJgg7kAnCDmSCsAOZIOxAJn5W4+yRe+65J6ynlqm+5ZZbwvoxxxTfVZ999lnYNjVenNo++NFHHw3r0ZLMqXnXqW2PU1s+R3PGJWn69OL9Q5YvXx62Tc2lj5apluJzBK6//vqwbbVS93tqznokWv47WracZ3YgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJh1WxV/FO1t7d7qVSqy3VH65NL6bHslE8//bSwFm2hK6XXR588eXJYHzJkSFi/4YYbCmupsert27eH9dQ5BDNnzgzr0Trm9957b9h20KBBYT01lz619nvk5JNPDuvR2u1S+vE4bdq0wlp3d3fYtq2trbA2Z84cvfXWW33e6cl7w8zGm9kLZrbFzDab2W/Kx4eZ2Voz21q+PCV1XQCapz9/+o5IusXdp0qaIWmJmU2TdLuk5919iqTnyz8DaFHJsLv7LndfX/5+n6QtksZJmi9pZfnXVkq6ql6dBFC9n/SmxswmSDpf0uuSRrv7LqnnD4KkUQVtFptZycxKXV1d1fUWQMX6HXYzGyzpb5KWunvxanlHcfcV7t7u7u2pze4A1E+/wm5mA9UT9D+5+9/Lh3eb2dhyfaykzvp0EUAtJKe4Ws/YyeOStrj773uVVktaKOm+8uUz1XYmNQwYDeMMGDCgbtctSWPGjCmsPfzww2Hb1BBQqh5Nr01JTVHdtm1bWE8tNR0NA0nxUtK33npr2Pakk04K66mhuej/NDU9NjX8FU0zlaT9+/eH9Whp8pTofoly0J9H0SxJv5K00czeLh9bpp6Q/9XMFkn6WNIv+9tZAI2XDLu7vyyp6E/kJbXtDoB64XRZIBOEHcgEYQcyQdiBTBB2IBMttZR0aqw7Us1YdLWqGTOttylTplRVr6dJkyY17barlToHoBXxzA5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCaSYTez8Wb2gpltMbPNZvab8vG7zOwTM3u7/DWv/t0FUKn+7KxwRNIt7r7ezIZIetPM1pZrf3D3f61f9wDUSn/2Z98laVf5+31mtkXSuHp3DEBt/aT37GY2QdL5kl4vH7rJzDaY2RNmdkpBm8VmVjKzUldXV1WdBVC5fofdzAZL+pukpe6+V9IjkiZLalPPM//v+mrn7ivcvd3d20eOHFmDLgOoRL/CbmYD1RP0P7n73yXJ3Xe7e7e7fyfpUUnT69dNANXqz6fxJulxSVvc/fe9jo/t9WsLJG2qffcA1Ep/Po2fJelXkjaa2dvlY8skXWdmbZJcUoekX9elhwBqoj+fxr8sqa+N09fUvjsA6oUz6IBMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE+bujbsxsy5J23odGiFpT8M68NO0at9atV8SfatULft2hrv3uf5bQ8P+oxs3K7l7e9M6EGjVvrVqvyT6VqlG9Y2X8UAmCDuQiWaHfUWTbz/Sqn1r1X5J9K1SDelbU9+zA2icZj+zA2gQwg5koilhN7PLzew9M3vfzG5vRh+KmFmHmW0sb0NdanJfnjCzTjPb1OvYMDNba2Zby5d97rHXpL61xDbewTbjTb3vmr39ecPfs5vZAEn/I+mfJO2Q9Iak69z9nYZ2pICZdUhqd/emn4BhZhdL+lrSv7v7ueVjyyV97u73lf9QnuLu/9IifbtL0tfN3sa7vFvR2N7bjEu6StINauJ9F/Trn9WA+60Zz+zTJb3v7h+6+yFJf5E0vwn9aHnu/qKkz486PF/SyvL3K9XzYGm4gr61BHff5e7ry9/vk/T9NuNNve+CfjVEM8I+TtL2Xj/vUGvt9+6SnjOzN81scbM704fR7r5L6nnwSBrV5P4cLbmNdyMdtc14y9x3lWx/Xq1mhL2vraRaafxvlrtfIOkKSUvKL1fRP/3axrtR+thmvCVUuv15tZoR9h2Sxvf6+TRJO5vQjz65+87yZaekVWq9rah3f7+Dbvmys8n9+T+ttI13X9uMqwXuu2Zuf96MsL8haYqZTTSzYyVdK2l1E/rxI2Z2YvmDE5nZiZIuVettRb1a0sLy9wslPdPEvvxAq2zjXbTNuJp83zV9+3N3b/iXpHnq+UT+A0l3NKMPBf2aJOm/y1+bm903SU+q52XdYfW8Ilokabik5yVtLV8Oa6G+/YekjZI2qCdYY5vUt39Uz1vDDZLeLn/Na/Z9F/SrIfcbp8sCmeAMOiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMvG/PyqbpLxVak0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=3822\n",
    "print('神經網路預測是:',labelname_dict[result[n]])\n",
    "plt.imshow(x_test[n].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 369us/sample - loss: 0.0206 - accuracy: 0.8970\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查是否有產生 Overfitting 的問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料正確率為: 0.897\n"
     ]
    }
   ],
   "source": [
    "loss, acc = score\n",
    "print('測試資料正確率為:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將 Model 儲存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure:\n",
    "\n",
    "### Conv 3 x 3, 16 \n",
    "\n",
    "### Conv 5 x 5, 32\n",
    "\n",
    "### Conv 5 x 5, 64\n",
    "\n",
    "### Conv 3 x 3, 128\n",
    "\n",
    "### loss funtion = mae\n",
    "\n",
    "### Optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "### Batch size = 100\n",
    "\n",
    "### epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
